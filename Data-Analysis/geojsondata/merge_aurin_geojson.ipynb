{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import couchdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to store all data. sa4 as key.\n",
    "data_dict = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Tweet Counts and Sentiment scores for each SA4 (Must be Tunneled into Couchdb instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'admin'\n",
    "password = 'password'\n",
    "COUCH_ADDRESS = 'localhost'\n",
    "\n",
    "# Connect to Couch DB Server\n",
    "# server = couchdb.Server(\"http://{}:{}@{}:5984/\".format(user, password, COUCH_ADDRESS))\n",
    "server = couchdb.Server(\"http://{}:{}@{}:15984/\".format(user, password, COUCH_ADDRESS))\n",
    "db = server['tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_counts = {}\n",
    "sent_sum = {}\n",
    "# Store Tweet Counts\n",
    "for code in db.view('Results/TweetCount', group='true'):\n",
    "    tweet_counts[code.key] = code.value\n",
    "\n",
    "# Store Sentiment Scores\n",
    "for code in db.view('Results/SentimentSum', group='true'):\n",
    "    sent_sum[code.key] = code.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tweet_counts.keys():\n",
    "    count = tweet_counts[key]\n",
    "    sent = sent_sum[key]\n",
    "    score = sent/count\n",
    "    \n",
    "    # store in data dict\n",
    "    data_dict[key]['sentiment_score'] = score\n",
    "    data_dict[key]['tweet_counts'] = count\n",
    "    data_dict[key]['sent_sum'] = sent\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data from Aurin & SA4 Geojson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sa4 geojson file and aurin data files\n",
    "sa4_geo_file = json.load(open('SA4_geojson.json'))\n",
    "sa4_centroids = json.load(open('sa4_geojson_centroid.json'))\n",
    "\n",
    "\n",
    "# crime data needs lga_sa4 conversion\n",
    "crime_data = json.load(open('crimedata.json'))\n",
    "income_data = json.load(open('equivalisedincomedata.json'))\n",
    "family_data = json.load(open('familycommunitydata.json'))\n",
    "unemployment_data = json.load(open('SA4_unemployment.json'))\n",
    "population_data = json.load(open('populationdata.json'))\n",
    "\n",
    "lga_sa4 = open('lga_sa4.csv', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sa4 lga conversion\n",
    "lga_sa4_dict = defaultdict(list)\n",
    "for line in lga_sa4:\n",
    "    line = line.strip('\\n')\n",
    "    (lga, sa4) = line.split(\",\")\n",
    "    lga_sa4_dict[lga] = sa4\n",
    "    \n",
    "# Create DF for data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_aurin(data_set, features):\n",
    "    for feature in features:\n",
    "        for item in data_set['features']:\n",
    "            if item['properties']['sa4_code_2016'] in data_dict.keys():\n",
    "                data_dict[item['properties']['sa4_code_2016']][feature] = item['properties'][feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dict(key, d, val):\n",
    "    if key in d:\n",
    "        d[key] = d[key] + val\n",
    "    else:\n",
    "        d[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process crime sa4_lga conversion\n",
    "# Add sa4 to each LGA in crime_data\n",
    "for item in crime_data['features']:\n",
    "    if item['properties']['lga_code'] in lga_sa4_dict.keys():\n",
    "        \n",
    "        a = item['properties']['total_division_a_offences']\n",
    "        b = item['properties']['total_division_b_offences']\n",
    "        c = item['properties']['total_division_c_offences']\n",
    "        d = item['properties']['total_division_d_offences']\n",
    "        e = item['properties']['total_division_e_offences']\n",
    "        f = item['properties']['total_division_f_offences']\n",
    "        sum_crimes = a+b+c+d+e+f\n",
    "        \n",
    "        item['properties']['sa4_code_2016'] = lga_sa4_dict[item['properties']['lga_code']]\n",
    "        item['properties']['sum_crimes'] = sum_crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process income and family features\n",
    "income_features = ['equivalised_total_household_income_census_median_weekly']\n",
    "family_features = ['rent_mortgage_payments_census_average_monthly_household_payment']\n",
    "crime_features = ['total_division_a_offences', 'total_division_b_offences', 'total_division_c_offences', \n",
    "                  'total_division_d_offences', 'total_division_e_offences', 'total_division_f_offences', \n",
    "                  'sum_crimes']\n",
    "process_aurin(income_data, income_features)\n",
    "process_aurin(family_data, family_features)\n",
    "process_aurin(crime_data, crime_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process for Unemployment job search weeks data\n",
    "for item in unemployment_data['features']:\n",
    "    if str(item['properties']['sa4_code']) in data_dict.keys():\n",
    "        data_dict[str(item['properties']['sa4_code'])]['unemployed_rate'] = item['properties']['unemployed_tot_000']\n",
    "        data_dict[str(item['properties']['sa4_code'])]['avg_duration_job_search_wks'] = item['properties']['avg_duration_job_search_wks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add population data\n",
    "for item in population_data['features']:\n",
    "    if item['properties']['sa4_code16'] in data_dict.keys():\n",
    "        data_dict[item['properties']['sa4_code16']]['persons_total'] = item['properties']['persons_total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put centroid in\n",
    "for item in sa4_centroids['features']:\n",
    "    if item['properties']['SA4_CODE16'] in data_dict.keys():\n",
    "        data_dict[item['properties']['SA4_CODE16']]['centroid'] = item['geometry']['coordinates']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'101'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_data['features'][0]['properties']['sa4_code16']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment_score': 0.008370183196462414,\n",
       " 'tweet_counts': 18996,\n",
       " 'sent_sum': 159,\n",
       " 'equivalised_total_household_income_census_median_weekly': 774,\n",
       " 'rent_mortgage_payments_census_average_monthly_household_payment': 1890,\n",
       " 'unemployed_rate': 9.20597806,\n",
       " 'avg_duration_job_search_wks': 13.63987744,\n",
       " 'persons_total': 339236,\n",
       " 'centroid': [151.29, -33.31]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict['102']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment score vs household income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Output json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output processed geojson\n",
    "def merge_data(data, sa4_geo):\n",
    "    output={\"type\": \"FeatureCollection\", \"features\":[]}\n",
    "    for row in sa4_geo['features']:\n",
    "        key = row['properties']['SA4_CODE16']\n",
    "        if key in data.keys():\n",
    "            for feature in data[key].keys():\n",
    "                row['properties'][feature]= data[key][feature]\n",
    "        else:\n",
    "            for feature in data[key].keys():\n",
    "                row['properties'][feature]='No Record'\n",
    "   \n",
    "    with open('output.json', 'w') as outfile:\n",
    "        json.dump(sa4_geo, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_data(data_dict, sa4_geo_file)\n",
    "# check = json.load(open('output.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in check['features']:\n",
    "#     if item['properties']['SA4_CODE16'] == '117':\n",
    "#         print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['101', '102', '103', '104', '106', '107', '108', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '301', '302', '303', '304', '305', '306', '307', '309', '310', '311', '312', '313', '314', '316', '317', '318', '319', '401', '402', '403', '404', '405', '406', '407', '501', '502', '503', '504', '505', '506', '509', '601', '602', '603', '604', '701', '702', '801'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
