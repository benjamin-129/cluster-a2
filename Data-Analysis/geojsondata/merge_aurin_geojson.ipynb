{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import couchdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict to store all data. sa4 as key.\n",
    "data_dict = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Tweet Counts and Sentiment scores for each SA4 (Must be Tunneled into Couchdb instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'admin'\n",
    "password = 'password'\n",
    "COUCH_ADDRESS = 'localhost'\n",
    "\n",
    "# Connect to Couch DB Server\n",
    "# server = couchdb.Server(\"http://{}:{}@{}:5984/\".format(user, password, COUCH_ADDRESS))\n",
    "server = couchdb.Server(\"http://{}:{}@{}:15984/\".format(user, password, COUCH_ADDRESS))\n",
    "db = server['tweets']\n",
    "\n",
    "front_end_db = server['front_end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_counts = {}\n",
    "sent_sum = {}\n",
    "# Store Tweet Counts\n",
    "for code in db.view('Results/TweetCount', group='true'):\n",
    "    tweet_counts[code.key] = code.value\n",
    "\n",
    "# Store Sentiment Scores\n",
    "for code in db.view('Results/SentimentSum', group='true'):\n",
    "    sent_sum[code.key] = code.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tweet_counts.keys():\n",
    "    count = tweet_counts[key]\n",
    "    sent = sent_sum[key]\n",
    "    score = sent/count\n",
    "    \n",
    "    # store in data dict\n",
    "    data_dict[key]['sentiment_score'] = score\n",
    "    data_dict[key]['tweet_counts'] = count\n",
    "    data_dict[key]['sent_sum'] = sent\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process data from Aurin & SA4 Geojson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sa4 geojson file and aurin data files\n",
    "sa4_geo_file = json.load(open('SA4_geojson.json'))\n",
    "sa4_centroids = json.load(open('sa4_geojson_centroid.json'))\n",
    "\n",
    "\n",
    "# crime data needs lga_sa4 conversion\n",
    "crime_data = json.load(open('crimedata.json'))\n",
    "income_data = json.load(open('equivalisedincomedata.json'))\n",
    "family_data = json.load(open('familycommunitydata.json'))\n",
    "unemployment_data = json.load(open('SA4_unemployment.json'))\n",
    "population_data = json.load(open('populationdata.json'))\n",
    "industry_data = json.load(open('industry.json'))\n",
    "socio_advantage_data = json.load(open('socioirsaddata.json'))\n",
    "personal_income = json.load(open('personalincomedata.json'))\n",
    "\n",
    "lga_sa4 = open('lga_sa4.csv', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sa4 lga conversion\n",
    "lga_sa4_dict = defaultdict(list)\n",
    "for line in lga_sa4:\n",
    "    line = line.strip('\\n')\n",
    "    (lga, sa4) = line.split(\",\")\n",
    "    lga_sa4_dict[lga] = sa4\n",
    "    \n",
    "# Create DF for data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_aurin(data_set, features):\n",
    "\n",
    "    for feature in features:\n",
    "        try:\n",
    "            for item in data_set['features']:\n",
    "                if item['properties']['sa4_code_2016'] in data_dict.keys():\n",
    "                    data_dict[item['properties']['sa4_code_2016']][feature] = item['properties'][feature]\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_dict(key, d, val):\n",
    "    if key in d:\n",
    "        d[key] = d[key] + val\n",
    "    else:\n",
    "        d[key] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process crime sa4_lga conversion\n",
    "# Add sa4 to each LGA in crime_data\n",
    "for item in crime_data['features']:\n",
    "    if item['properties']['lga_code'] in lga_sa4_dict.keys():\n",
    "        \n",
    "        a = item['properties']['total_division_a_offences']\n",
    "        b = item['properties']['total_division_b_offences']\n",
    "        c = item['properties']['total_division_c_offences']\n",
    "        d = item['properties']['total_division_d_offences']\n",
    "        e = item['properties']['total_division_e_offences']\n",
    "        f = item['properties']['total_division_f_offences']\n",
    "        sum_crimes = a+b+c+d+e+f\n",
    "        \n",
    "        item['properties']['sa4_code_2016'] = lga_sa4_dict[item['properties']['lga_code']]\n",
    "        item['properties']['sum_crimes'] = sum_crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sa4 to each LGA in soci_advantage_data\n",
    "# for item in socio_advantage_data['features']:\n",
    "#     if item['properties']['lga_code_2006_'] in lga_sa4_dict.keys():\n",
    "#         item['properties']['sa4_code_2016'] = lga_sa4_dict[item['properties']['lga_code_2006_']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process income and family features\n",
    "income_features = ['equivalised_total_household_income_census_median_weekly']\n",
    "family_features = ['rent_mortgage_payments_census_average_monthly_household_payment', 'sa4_name_2016']\n",
    "# crime_features = ['total_division_a_offences', 'total_division_b_offences', 'total_division_c_offences', \n",
    "#                   'total_division_d_offences', 'total_division_e_offences', 'total_division_f_offences', \n",
    "#                   'sum_crimes']\n",
    "# socio_features = ['irsad_score']\n",
    "personal_income_features = ['mean_aud', 'median_aud']\n",
    "\n",
    "process_aurin(income_data, income_features)\n",
    "process_aurin(family_data, family_features)\n",
    "process_aurin(personal_income, personal_income_features)\n",
    "# process_aurin(crime_data, crime_features)\n",
    "# process_aurin(socio_advantage_data, socio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process for Unemployment job search weeks data\n",
    "# for item in unemployment_data['features']:\n",
    "#     if str(item['properties']['sa4_code']) in data_dict.keys():\n",
    "#         data_dict[str(item['properties']['sa4_code'])]['unemployed_rate'] = item['properties']['unemployed_tot_000']\n",
    "#         data_dict[str(item['properties']['sa4_code'])]['avg_duration_job_search_wks'] = item['properties']['avg_duration_job_search_wks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add population data\n",
    "# for item in population_data['features']:\n",
    "#     if item['properties']['sa4_code16'] in data_dict.keys():\n",
    "#         data_dict[item['properties']['sa4_code16']]['persons_total'] = item['properties']['persons_total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put centroid in\n",
    "for item in sa4_centroids['features']:\n",
    "    if item['properties']['SA4_CODE16'] in data_dict.keys():\n",
    "        data_dict[item['properties']['SA4_CODE16']]['centroid'] = item['geometry']['coordinates']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in industry_data['features']:\n",
    "#     if item['properties']['sa4_code_2016'] in data_dict.keys():\n",
    "#         data_dict[item['properties']['sa4_code_2016']]['num_recreation_busi'] = item['properties']['number_businesses_industry_30_june_arts_recreation_services_num']\n",
    "#         data_dict[item['properties']['sa4_code_2016']]['num_scientific_busi'] = item['properties']['nmbr_bsnsss_indstry_30_jne_prfssnl_scntfc_tchncl_srvcs_nm']\n",
    "#         data_dict[item['properties']['sa4_code_2016']]['num_mining_busi'] = item['properties']['number_of_businesses_by_industry_as_at_30_june_mining_num']\n",
    "#         data_dict[item['properties']['sa4_code_2016']]['num_finance_busi'] = item['properties']['nmbr_bsnsss_indstry_30_jne_fnncl_insrnce_srvcs_nm']\n",
    "#         data_dict[item['properties']['sa4_code_2016']]['num_agri_busi'] = item['properties']['nmbr_bsnsss_indstry_30_jne_agrcltre_frstry_fshng_nm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personal_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = []\n",
    "# for key, value in data_dict.items():\n",
    "#     curr_d = value\n",
    "#     curr_d['sa4_code'] = key\n",
    "#     out.append(curr_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Sentiment Scores periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get file from DB\n",
    "in_file = front_end_db.get_attachment('test_3', 'output_123.json').read()\n",
    "in_json = json.loads(in_file.decode('utf8').replace(\"'\", '\"'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_json[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sentiment score and normalised sentiment score\n",
    "sentiment_score = {}\n",
    "for key in tweet_counts.keys():\n",
    "    count = tweet_counts[key]\n",
    "    sent = sent_sum[key]\n",
    "    score = sent/count\n",
    "    \n",
    "    sentiment_score[key] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update file\n",
    "for item in in_json:\n",
    "    if item['sa4_code'] in sentiment_score.keys():\n",
    "        key = item['sa4_code']\n",
    "        item['sentiment_score'] = sentiment_score[key]\n",
    "        item['sent_sum'] = sent_sum[key]\n",
    "        item['tweet_counts'] = tweet_counts[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put attachment to DB\n",
    "doc = front_end_db['test_3']\n",
    "front_end_db.put_attachment(doc, in_json, 'out_data.json', \"application/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of tweet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df=pd.DataFrame.from_dict(data_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "scaler_data = np.array(data_df.sentiment_score).reshape(-1, 1)\n",
    "sentiment_scaled = min_max_scaler.fit_transform(scaler_data)\n",
    "data_df['sentiment_scaled'] = sentiment_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_out = data_df.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set_theme(color_codes=True)\n",
    "\n",
    "\n",
    "ax = sns.regplot(x=\"equivalised_total_household_income_census_median_weekly\", y=\"sentiment_score\", data=data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Output json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output processed geojson\n",
    "def merge_data(data, sa4_geo):\n",
    "    output={\"type\": \"FeatureCollection\", \"features\":[]}\n",
    "    for row in sa4_geo['features']:\n",
    "        key = row['properties']['SA4_CODE16']\n",
    "        if key in data.keys():\n",
    "            for feature in data[key].keys():\n",
    "                row['properties'][feature]= data[key][feature]\n",
    "        else:\n",
    "            for feature in data[key].keys():\n",
    "                row['properties'][feature]='No Record'\n",
    "   \n",
    "    with open('output.json', 'w') as outfile:\n",
    "        json.dump(sa4_geo, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_data(data_dict, sa4_geo_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check = json.load(open('output.json'))\n",
    "# for item in check['features']:\n",
    "#     if item['properties']['SA4_CODE16'] == '117':\n",
    "#         print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa4_geo_file['features'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
